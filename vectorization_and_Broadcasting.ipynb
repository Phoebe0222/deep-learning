{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vectorization and Broadcasting.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Phoebe0222/deep-learning/blob/master/vectorization_and_Broadcasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "zCAOGywB1-Oe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Vectorization in Python\n",
        "\n",
        "Thanks to the package Numpy, vectorizing data has become so handy, and more importantly computing time has reduced greatrly comparing to using for loop. Following is the example from the course [Neural Networks and Deep Learning](https://www.coursera.org/learn/neural-networks-deep-learning/lecture/ZPlX9/more-vectorization-examples), which has shown vectorization outruns for-loop in terms of computing time.\n",
        "\n",
        "We want to calculate: \n",
        "\\begin{equation}  \n",
        "\\sum_{i=1}^{1000000} a_i*b_i, where \\  a_i \\  and \\  b_i \\space are \\  random \\ numbers\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "x4tG5XXSx5UG",
        "colab_type": "code",
        "outputId": "01aa04fc-c1c1-4844-c486-09520fa1e7bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "a = np.random.rand(1000000)\n",
        "b = np.random.rand(1000000)\n",
        "\n",
        "#vectorization\n",
        "tic = time.time()\n",
        "c = np.dot(a,b) #transpose of a times b\n",
        "toc = time.time()\n",
        "print(\"Vectorized version:\" + str(1000*(toc-tic)) + \"ms\" + \" and c =\" + str(c))\n",
        "\n",
        "#for loop (explicit expression)\n",
        "c = 0\n",
        "tic = time.time()\n",
        "for i in range(1000000):\n",
        "    c += a[i]*b[i] \n",
        "toc = time.time()\n",
        "print(\"for loop:\" + str(1000*(toc-tic))+\"ms\"+ \" and c =\" + str(c))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vectorized version:0.7493495941162109ms and c =250652.21687471058\n",
            "for loop:458.0113887786865ms and c =250652.21687471532\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rNOLvVey5Pkj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So vectorization has reduced computing time greatly as shown above. Note that there are many other methods we can call on numpy other than the dot product of two vectors, such as exponential, logrithm etc. "
      ]
    },
    {
      "metadata": {
        "id": "65mu2DUF6dIL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "7a75353c-d2aa-4ad3-8694-53d3f3c81fb8"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "n=100\n",
        "u_zero = np.zeros((n,1))\n",
        "v = np.random.rand(100)\n",
        "u_exp = np.exp(v).reshape(100,1)\n",
        "u_log = np.log(v)\n",
        "u_ads = np.abs(v)\n",
        "u_max = np.maximum(v,0.5)\n",
        "u_sq = v**2\n",
        "u_reci = 1/v\n",
        "\n",
        "print(u_exp[0:5])\n",
        "print(u_max[0:5])\n",
        "print(np.dot(u_max,u_exp))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.93149031]\n",
            " [2.01497048]\n",
            " [2.08274495]\n",
            " [1.26232461]\n",
            " [2.04198797]]\n",
            "[0.65829189 0.70060455 0.73368671 0.5        0.71392383]\n",
            "[112.77503669]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EHSWGPL4hbKm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Broadcasting\n",
        "Another useful feature in Python is known as broadcasting. The general principle is as follow:\n",
        "\n",
        "\\begin{equation}  \n",
        "Let \\ A_{m,n} = \n",
        " \\begin{pmatrix}\n",
        "  a_{1,1} & a_{1,2} & \\cdots & a_{1,n} \\\\\n",
        "  a_{2,1} & a_{2,2} & \\cdots & a_{2,n} \\\\\n",
        "  \\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
        "  a_{m,1} & a_{m,2} & \\cdots & a_{m,n} \n",
        " \\end{pmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "and \n",
        "\\begin{equation}  \n",
        "\\ B_{1,n} = \n",
        " \\begin{pmatrix}\n",
        "  b_{1,1} & b_{1,2} & \\cdots & b_{1,n} \n",
        " \\end{pmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "and\n",
        "\\begin{equation}  \n",
        "\\ C_{m,1} = \n",
        " \\begin{pmatrix}\n",
        "  c_{1,1} \\\\\n",
        "  c_{2,1}\\\\\n",
        "  \\vdots\\\\\n",
        "  c_{m,1}\n",
        " \\end{pmatrix}\n",
        "\\end{equation}\n",
        "Then\n",
        "\\begin{equation}  \n",
        "\\ A_{m,n}+B_{1,n} = \n",
        " \\begin{pmatrix}\n",
        "  a_{1,1} + b_{1,1} & a_{1,2} + b_{1,2} & \\cdots & a_{1,n} + b_{1,n}  \\\\\n",
        "  a_{2,1} + b_{1,1} & a_{2,2} + b_{1,2}  & \\cdots & a_{2,n}+ b_{1,n} \\\\\n",
        "  \\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
        "  a_{m,1}  + b_{1,1}& a_{m,2} + b_{1,2}  & \\cdots & a_{m,n}+ b_{1,n} \n",
        " \\end{pmatrix}\n",
        "\\end{equation}\n",
        "and\n",
        "\\begin{equation}  \n",
        "\\ A_{m,n}+C_{m,1} = \n",
        " \\begin{pmatrix}\n",
        "  a_{1,1} + c_{1,1} & a_{1,2} + c_{1,1} & \\cdots & a_{1,n} + c_{1,1} \\\\\n",
        "  a_{2,1} +  c_{2,1} & a_{2,2} + c_{2,1} & \\cdots & a_{2,n}+  c_{2,1}\\\\\n",
        "  \\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
        "  a_{m,1}  +  c_{m,1}& a_{m,2} +  c_{m,1}  & \\cdots & a_{m,n}+  c_{m,1}\n",
        " \\end{pmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "Note that broadcasting also works for deduction, multiplication and division, but always always check  if thhe output is the desired one. Sometimes there might be matrix mismatch so the following are some examples on how to ensure the correct size of the matrix. "
      ]
    },
    {
      "metadata": {
        "id": "D-z_olZekzqE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "11a3f7b9-9f11-4cf5-9dc5-82f6b30fd8c0"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#create a rank 1 array, should avoid using\n",
        "a = np.random.randn(5) \n",
        "print(a.shape)\n",
        "\n",
        "#create a colunm vector\n",
        "a = np.random.randn(5,1) \n",
        "print(a.shape)\n",
        "\n",
        "#create a row vector\n",
        "a = np.random.randn(1,5) \n",
        "print(a.shape)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5,)\n",
            "(5, 1)\n",
            "(1, 5)\n",
            "(5,)\n",
            "[ 1.92944402 -0.04552309 -0.67826538 -0.08640671 -1.55323573]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}