{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tensorflow.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"EOK03WttYhyx","colab_type":"text"},"cell_type":"markdown","source":["# Tensorflow\n","This notebook includes my notes from learning Tensorflow from [the lesson *Programming* *Frameworks* by deeplearning.ai](https://www.coursera.org/learn/deep-neural-network/lecture/zcZlH/tensorflow)."]},{"metadata":{"id":"G5_PsB83efyM","colab_type":"text"},"cell_type":"markdown","source":["### Broad Structure of Tensorflow\n","\n","\n","Let's start with a simpler example. Suppose we want to minimise \\begin{equation}  \n","J(w) = w^2 - 10w + 25\n","\\end{equation}\n","\n","Let's say we don't know the answer is 5. Now let's use Tensorflow to minimise this. "]},{"metadata":{"id":"Yr025L_jeXKQ","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf"],"execution_count":0,"outputs":[]},{"metadata":{"id":"50fvRSq5BqCV","colab_type":"text"},"cell_type":"markdown","source":["\n","First we need to initialize w to 0 and define a cost function; \n","\n","Then define train to be the learning algorithm, which is a gradient descent optimizer, with learning rate of 0.01."]},{"metadata":{"id":"tK1LgJBGhkSh","colab_type":"code","colab":{}},"cell_type":"code","source":["w = tf.Variable(0,dtype=tf.float32)\n","#cost = tf.add(tf.add(w**2, tf.multiply(-10.,w)),25)\n","cost = w**2 - 10*w + 25 #or we can use this simpler expression\n","train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5HIrFKYxBNIi","colab_type":"text"},"cell_type":"markdown","source":["The next 3 lines start a Tensorflow session. \n"]},{"metadata":{"id":"YBS5qm2KBJVb","colab_type":"code","colab":{}},"cell_type":"code","source":["init = tf.global_variables_initializer()\n","session = tf.Session()\n","session.run(init)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oM5_sNoRE_o2","colab_type":"text"},"cell_type":"markdown","source":["To evaluate w, we need to use session.run(w). Since we haven't run the algorithm yet, w is 0 as we initialize it. "]},{"metadata":{"id":"8Hf9ATv0E9PG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"4c00c5ed-243f-4c46-8ad7-493b25f9fb04","executionInfo":{"status":"ok","timestamp":1550556197888,"user_tz":-480,"elapsed":667,"user":{"displayName":"Phoebe Liang","photoUrl":"https://lh3.googleusercontent.com/-MgDnW4gBqVg/AAAAAAAAAAI/AAAAAAAAC78/aG9KTBm96UU/s64/photo.jpg","userId":"04768959665622642599"}}},"cell_type":"code","source":["print(session.run(w))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["0.0\n"],"name":"stdout"}]},{"metadata":{"id":"9ja9UM2iDeIg","colab_type":"text"},"cell_type":"markdown","source":["Now let's run one iteration of the algorithm and evaluate w again. "]},{"metadata":{"id":"kczs7kF-ED_6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"2a8771a4-9db2-4a3c-e920-aee4607d589c","executionInfo":{"status":"ok","timestamp":1550556200547,"user_tz":-480,"elapsed":1014,"user":{"displayName":"Phoebe Liang","photoUrl":"https://lh3.googleusercontent.com/-MgDnW4gBqVg/AAAAAAAAAAI/AAAAAAAAC78/aG9KTBm96UU/s64/photo.jpg","userId":"04768959665622642599"}}},"cell_type":"code","source":["session.run(train)\n","print(session.run(w))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["0.099999994\n"],"name":"stdout"}]},{"metadata":{"id":"YXlyaU2FBDAL","colab_type":"text"},"cell_type":"markdown","source":["Finally let's run 1000 iterations and wwe can see it's very close to 5."]},{"metadata":{"id":"bNHfKJcXFzpu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"515efec3-02fc-43b2-d29b-0079a04d3eaf","executionInfo":{"status":"ok","timestamp":1550556206517,"user_tz":-480,"elapsed":676,"user":{"displayName":"Phoebe Liang","photoUrl":"https://lh3.googleusercontent.com/-MgDnW4gBqVg/AAAAAAAAAAI/AAAAAAAAC78/aG9KTBm96UU/s64/photo.jpg","userId":"04768959665622642599"}}},"cell_type":"code","source":["for i in range(1000):\n","  session.run(train)\n","print(session.run(w))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["4.999988\n"],"name":"stdout"}]},{"metadata":{"id":"VwYcDdE9Lnvp","colab_type":"text"},"cell_type":"markdown","source":["As we can see, we only need to initialize parameters and define the cost funtion (i.e. forwardprop), and tensorflow will compute the backward propogation using a few commands. Now we have seen the broad structure of Tensorflow:\n","\n","*   define forward propagation \n","*   start a Tensorflow session\n","*   run iterations of the algorithm \n","*   evaluate the variables \n","\n"]},{"metadata":{"id":"rWyZZQHpYQZl","colab_type":"text"},"cell_type":"markdown","source":["### Import data into Tensorflow"]},{"metadata":{"id":"QTB23zAYXxm8","colab_type":"text"},"cell_type":"markdown","source":["Since the cost function of neural network is a function of the traning set, let's now see how we can get training data into a Tensorflow program. "]},{"metadata":{"id":"OGUvRt8sYPNp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"2712ac2b-03b0-4c4b-c520-f8b654ff0777","executionInfo":{"status":"ok","timestamp":1550558378416,"user_tz":-480,"elapsed":1057,"user":{"displayName":"Phoebe Liang","photoUrl":"https://lh3.googleusercontent.com/-MgDnW4gBqVg/AAAAAAAAAAI/AAAAAAAAC78/aG9KTBm96UU/s64/photo.jpg","userId":"04768959665622642599"}}},"cell_type":"code","source":["# putting data\n","coefficients = np.array([[1,],[-20],[100]]) \n","\n","# forward propagation\n","w = tf.Variable(0,dtype=tf.float32)\n","x = tf.placeholder(tf.float32, [3,1]) # define x to be a 3 by 1 matrix just as the coefficients \n","        # the placeholder function tells Tensorflow that x is something that we provide the values for later\n","cost = x[0][0]*w**2 + x[1][0]*w + x[2][0]\n","train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n","\n","# start a Tensorflow session\n","init = tf.global_variables_initializer()\n","session = tf.Session() \n","session.run(init)\n","  # alternatively, \n","  # with tf.Session() as session:\n","  #     session.run(init)\n","\n","# run iterations of the algorithm\n","for i in range(1000):\n","  session.run(train, feed_dict={x:coefficients}) # now we assign the values of x\n","\n","# evaluate the parameters   \n","print(session.run(w))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["9.999976\n"],"name":"stdout"}]},{"metadata":{"id":"YcFJ_Dq8kBpI","colab_type":"text"},"cell_type":"markdown","source":["If we want to put mini-batches into x on each iteration, we need to use the feed_dict to feed in different subsets of the training sets. So we have seen that Tensorflow can help us so much more efficiently implement neural netrwork. "]}]}